{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:11:38.255738Z",
     "start_time": "2024-07-01T20:11:37.593711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "!pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.types import *"
   ],
   "id": "acf9a3404fb150f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: pyspark in /home/fmalaspina/.local/lib/python3.10/site-packages (3.5.1)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/fmalaspina/.local/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:11:39.618716Z",
     "start_time": "2024-07-01T20:11:39.612645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = (SparkSession.builder.appName(\"itoss-ai\")\n",
    "         .config(\"spark.jars\",\"./postgresql-42.7.3.jar\")\n",
    "         .getOrCreate())"
   ],
   "id": "2a13f0308a39ae8",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:11:43.090069Z",
     "start_time": "2024-07-01T20:11:43.055252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "jdbcUrl = \"jdbc:postgresql://localhost:5432/itossconfig\"\n",
    "connection_properties = {\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"user\": \"itoss\",\n",
    "    \"password\": \"admin\"\n",
    "}\n",
    "query = \"(select c.*, w.name as ctWorkgroup, l.name as ctLocation from ct c \\\n",
    "         inner join workgroup w on c.workgroup_id = w.id \\\n",
    "         inner join location l on c.location_id = l.id \\\n",
    "         inner join ct_type ct on c.type_id = ct.id \\\n",
    ") as subquery\"  \n",
    "ctDf = spark.read.jdbc(url=jdbcUrl,table=query,properties=connection_properties)\n",
    "ctDf.printSchema()\n",
    "\n",
    "\n"
   ],
   "id": "2c0e60204ca1868b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- created_by: string (nullable = true)\n",
      " |-- creation_date: timestamp (nullable = true)\n",
      " |-- last_modified_by: string (nullable = true)\n",
      " |-- last_modified_date: timestamp (nullable = true)\n",
      " |-- attributes: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- environment: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- old_password: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- collector_id: long (nullable = true)\n",
      " |-- company_id: long (nullable = true)\n",
      " |-- contact_id: long (nullable = true)\n",
      " |-- location_id: long (nullable = true)\n",
      " |-- monitoring_profile_id: long (nullable = true)\n",
      " |-- support_user_id: long (nullable = true)\n",
      " |-- type_id: long (nullable = true)\n",
      " |-- workgroup_id: long (nullable = true)\n",
      " |-- instrumentation_parameter_values: string (nullable = true)\n",
      " |-- old_crypted_property_values: string (nullable = true)\n",
      " |-- integration_id: string (nullable = true)\n",
      " |-- ctworkgroup: string (nullable = true)\n",
      " |-- ctlocation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:11:47.109768Z",
     "start_time": "2024-07-01T20:11:47.082010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "queryStatusDelta = \"(select * from ct_status_delta) as subquery\"  \n",
    "ctStatusDeltaDf = spark.read.jdbc(url=jdbcUrl,table=queryStatusDelta,properties=connection_properties)\n",
    "ctStatusDeltaDf.printSchema()\n"
   ],
   "id": "6da343589b461759",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ct_id: long (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- last_status_change: timestamp (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T21:30:18.829736Z",
     "start_time": "2024-07-01T21:30:18.789773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import col, count, lit, when, current_timestamp, expr, collect_list, struct\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "import json\n",
    "\n",
    "# 1. Filter the ct_status_delta table to include only records within the last hour\n",
    "one_hour_ago = current_timestamp() - expr('INTERVAL 2 HOUR')\n",
    "filtered_status_delta = ctStatusDeltaDf.filter(col(\"last_status_change\") >= one_hour_ago)\n",
    "filtered_status_delta.show()"
   ],
   "id": "481a3dafdd18d2fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------------------+--------------------+\n",
      "| ct_id|status|  last_status_change|           timestamp|\n",
      "+------+------+--------------------+--------------------+\n",
      "|200148|    up|2024-07-01 17:06:...|2024-07-01 17:06:...|\n",
      "|200148|  down|2024-07-01 17:06:...|2024-07-01 17:06:...|\n",
      "|200147|  down|2024-07-01 17:06:...|2024-07-01 17:06:...|\n",
      "|200147|    up|2024-07-01 17:07:...|2024-07-01 17:07:...|\n",
      "|200148|  down|2024-07-01 18:19:...|2024-07-01 18:19:...|\n",
      "|200147|  down|2024-07-01 18:19:...|2024-07-01 18:19:...|\n",
      "|200146|  down|2024-07-01 18:19:...|2024-07-01 18:19:...|\n",
      "|200145|  down|2024-07-01 18:19:...|2024-07-01 18:19:...|\n",
      "+------+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T21:32:05.755048Z",
     "start_time": "2024-07-01T21:32:05.542990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import row_number, lag, sum as spark_sum\n",
    "from pyspark.sql import Window\n",
    "\n",
    "windowSpec = Window.partitionBy(\"ct_id\").orderBy(filtered_status_delta.last_status_change)\n",
    "statusDeltaDf = filtered_status_delta.withColumn(\"prev_status\", lag(\"status\").over(windowSpec))\n",
    "\n",
    "df_trend = statusDeltaDf.withColumn(\n",
    "    \"change\",\n",
    "    when((col(\"status\") == \"up\") & (col(\"prev_status\") == \"down\"), \"improving\")\n",
    "    .when((col(\"status\") == \"down\") & (col(\"prev_status\") == \"up\"), \"worsening\")\n",
    "    .otherwise(\"no change\")\n",
    ")\n",
    "\n",
    "# Aggregate changes to determine the trend for each ct_id\n",
    "trend_summary = df_trend.groupBy().agg(\n",
    "    spark_sum(when(col(\"change\") == \"improving\", 1).otherwise(0)).alias(\"improving_count\"),\n",
    "    spark_sum(when(col(\"change\") == \"worsening\", 1).otherwise(0)).alias(\"worsening_count\")\n",
    ")\n",
    "\n",
    "# Determine the final trend\n",
    "final_trend = trend_summary.withColumn(\n",
    "    \"trend\",\n",
    "    when(col(\"improving_count\") > col(\"worsening_count\"), \"Improving\")\n",
    "    .when(col(\"improving_count\") < col(\"worsening_count\"), \"Worsening\")\n",
    "    .otherwise(\"No change\")\n",
    ")\n",
    "df_trend.show(truncate=False)\n",
    "final_trend.show()\n",
    "\n",
    "df_trend.show(truncate=False)\n"
   ],
   "id": "f95d5c02dbade577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------------------------+--------------------------+-----------+---------+\n",
      "|ct_id |status|last_status_change        |timestamp                 |prev_status|change   |\n",
      "+------+------+--------------------------+--------------------------+-----------+---------+\n",
      "|200145|down  |2024-07-01 18:19:08.770353|2024-07-01 18:19:08.770353|NULL       |no change|\n",
      "|200146|down  |2024-07-01 18:19:08.759216|2024-07-01 18:19:08.759216|NULL       |no change|\n",
      "|200147|down  |2024-07-01 17:06:56.60581 |2024-07-01 17:06:56.60581 |NULL       |no change|\n",
      "|200147|up    |2024-07-01 17:07:08.670188|2024-07-01 17:07:08.670188|down       |improving|\n",
      "|200147|down  |2024-07-01 18:19:08.748226|2024-07-01 18:19:08.748226|up         |worsening|\n",
      "|200148|up    |2024-07-01 17:06:00.494579|2024-07-01 17:06:00.494579|NULL       |no change|\n",
      "|200148|down  |2024-07-01 17:06:27.129998|2024-07-01 17:06:27.129998|up         |worsening|\n",
      "|200148|down  |2024-07-01 18:19:08.736937|2024-07-01 18:19:08.736937|down       |no change|\n",
      "+------+------+--------------------------+--------------------------+-----------+---------+\n",
      "\n",
      "+---------------+---------------+---------+\n",
      "|improving_count|worsening_count|    trend|\n",
      "+---------------+---------------+---------+\n",
      "|              1|              2|Worsening|\n",
      "+---------------+---------------+---------+\n",
      "\n",
      "+------+------+--------------------------+--------------------------+-----------+---------+\n",
      "|ct_id |status|last_status_change        |timestamp                 |prev_status|change   |\n",
      "+------+------+--------------------------+--------------------------+-----------+---------+\n",
      "|200145|down  |2024-07-01 18:19:08.770353|2024-07-01 18:19:08.770353|NULL       |no change|\n",
      "|200146|down  |2024-07-01 18:19:08.759216|2024-07-01 18:19:08.759216|NULL       |no change|\n",
      "|200147|down  |2024-07-01 17:06:56.60581 |2024-07-01 17:06:56.60581 |NULL       |no change|\n",
      "|200147|up    |2024-07-01 17:07:08.670188|2024-07-01 17:07:08.670188|down       |improving|\n",
      "|200147|down  |2024-07-01 18:19:08.748226|2024-07-01 18:19:08.748226|up         |worsening|\n",
      "|200148|up    |2024-07-01 17:06:00.494579|2024-07-01 17:06:00.494579|NULL       |no change|\n",
      "|200148|down  |2024-07-01 17:06:27.129998|2024-07-01 17:06:27.129998|up         |worsening|\n",
      "|200148|down  |2024-07-01 18:19:08.736937|2024-07-01 18:19:08.736937|down       |no change|\n",
      "+------+------+--------------------------+--------------------------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T21:39:44.032505Z",
     "start_time": "2024-07-01T21:39:43.895385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df_last_status_count = statusDeltaDf.withColumn(\"row_num\", row_number().over(windowSpec)).filter(col(\"row_num\") == 1).drop(\"row_num\").groupBy(\"status\").count()\n",
    "\n",
    "df_last_status_count.show(truncate=False)"
   ],
   "id": "f16e76a86731392c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|status|count|\n",
      "+------+-----+\n",
      "|down  |3    |\n",
      "|up    |1    |\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:45:39.550110Z",
     "start_time": "2024-07-01T20:45:39.529207Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "f565670503f2ffb1",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[122], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m trend_summary \u001B[38;5;241m=\u001B[39m df_trend\u001B[38;5;241m.\u001B[39mgroupBy(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mct_id\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39magg(\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28msum\u001B[39m(\n\u001B[0;32m----> 3\u001B[0m         when(\u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mchange\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mequalsTo\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimproving\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39motherwise(\u001B[38;5;241m0\u001B[39m))\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimproving_count\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28msum\u001B[39m(when(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchange\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mequalsTo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mworsening\u001B[39m\u001B[38;5;124m\"\u001B[39m), \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39motherwise(\u001B[38;5;241m0\u001B[39m))\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mworsening_count\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m )\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Determine the final trend for each ct_id\u001B[39;00m\n\u001B[1;32m      8\u001B[0m final_trend \u001B[38;5;241m=\u001B[39m trend_summary\u001B[38;5;241m.\u001B[39mwithColumn(\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrend\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m     when(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimproving_count\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m>\u001B[39m col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mworsening_count\u001B[39m\u001B[38;5;124m\"\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImproving\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;241m.\u001B[39mwhen(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimproving_count\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m<\u001B[39m col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mworsening_count\u001B[39m\u001B[38;5;124m\"\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWorsening\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;241m.\u001B[39motherwise(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo change\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     13\u001B[0m )\n",
      "\u001B[0;31mTypeError\u001B[0m: 'Column' object is not callable"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `status` cannot be resolved. Did you mean one of the following? [`state`, `name`, `id`, `key`, `type_id`].;\n'Aggregate ['status], ['status, count(1) AS total_count#6578L]\n+- Relation [id#6364L,created_by#6365,creation_date#6366,last_modified_by#6367,last_modified_date#6368,attributes#6369,key#6370,environment#6371,name#6372,old_password#6373,state#6374,collector_id#6375L,company_id#6376L,contact_id#6377L,location_id#6378L,monitoring_profile_id#6379L,support_user_id#6380L,type_id#6381L,workgroup_id#6382L,instrumentation_parameter_values#6383,old_crypted_property_values#6384,integration_id#6385,ctworkgroup#6386,ctlocation#6387] JDBCRelation((select c.*, w.name as ctWorkgroup, l.name as ctLocation from ct c          inner join workgroup w on c.workgroup_id = w.id          inner join location l on c.location_id = l.id          inner join ct_type ct on c.type_id = ct.id ) as subquery) [numPartitions=1]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[115], line 9\u001B[0m\n\u001B[1;32m      5\u001B[0m statusCounts \u001B[38;5;241m=\u001B[39m joinedDf\u001B[38;5;241m.\u001B[39mgroupBy(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39magg(count(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcount_last_hour\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#envCounts = joinedDf.groupBy(\"environment\").agg(count(\"*\").alias(\"count_last_hour\"))\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Calculate total counts in the ct table\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m total_statusCounts \u001B[38;5;241m=\u001B[39m \u001B[43mctDf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupBy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstatus\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcount\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m*\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malias\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtotal_count\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m#total_envCounts = ctDf.groupBy(\"environment\").agg(count(\"*\").alias(\"total_count\"))\u001B[39;00m\n\u001B[1;32m     12\u001B[0m statusCounts\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m5\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/group.py:186\u001B[0m, in \u001B[0;36mGroupedData.agg\u001B[0;34m(self, *exprs)\u001B[0m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(c, Column) \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m exprs), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall exprs should be Column\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    185\u001B[0m     exprs \u001B[38;5;241m=\u001B[39m cast(Tuple[Column, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m], exprs)\n\u001B[0;32m--> 186\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jgd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexprs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jc\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexprs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `status` cannot be resolved. Did you mean one of the following? [`state`, `name`, `id`, `key`, `type_id`].;\n'Aggregate ['status], ['status, count(1) AS total_count#6578L]\n+- Relation [id#6364L,created_by#6365,creation_date#6366,last_modified_by#6367,last_modified_date#6368,attributes#6369,key#6370,environment#6371,name#6372,old_password#6373,state#6374,collector_id#6375L,company_id#6376L,contact_id#6377L,location_id#6378L,monitoring_profile_id#6379L,support_user_id#6380L,type_id#6381L,workgroup_id#6382L,instrumentation_parameter_values#6383,old_crypted_property_values#6384,integration_id#6385,ctworkgroup#6386,ctlocation#6387] JDBCRelation((select c.*, w.name as ctWorkgroup, l.name as ctLocation from ct c          inner join workgroup w on c.workgroup_id = w.id          inner join location l on c.location_id = l.id          inner join ct_type ct on c.type_id = ct.id ) as subquery) [numPartitions=1]\n"
     ]
    }
   ],
   "execution_count": 115,
   "source": [
    "\n",
    "# 2. Join the filtered ct_status_delta table with the ct table\n",
    "joinedDf = ctDf.join(statusDeltaDf, ctDf.id == statusDeltaDf.ct_id, \"inner\")\n",
    "\n",
    "# 3. Calculate the counts for different statuses and environments within the last hour\n",
    "statusCounts = joinedDf.groupBy(\"status\").agg(count(\"*\").alias(\"count_last_hour\"))\n",
    "#envCounts = joinedDf.groupBy(\"environment\").agg(count(\"*\").alias(\"count_last_hour\"))\n",
    "\n",
    "# Calculate total counts in the ct table\n",
    "total_statusCounts = ctDf.groupBy(\"status\").agg(count(\"*\").alias(\"total_count\"))\n",
    "#total_envCounts = ctDf.groupBy(\"environment\").agg(count(\"*\").alias(\"total_count\"))\n",
    "\n",
    "statusCounts.show(5)\n",
    "#envCounts.show(5)\n",
    "total_statusCounts.show(5)\n",
    "#total_envCounts.show(5)\n",
    "\n"
   ],
   "id": "cc21c1087aa73365"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# 4. Calculate quantity and percentage variations\n",
    "statusCounts = statusCounts.join(total_statusCounts, \"ctStatus\") \\\n",
    "    .withColumn(\"quantityVariation\", col(\"count_last_hour\") - col(\"total_count\")) \\\n",
    "    .withColumn(\"percentageVariation\", col(\"quantityVariation\") / col(\"total_count\") * 100)\n",
    "statusCounts.printSchema()\n",
    "statusCounts.show(5)\n"
   ],
   "id": "f5fca6f1ecc98abe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#envCounts = envCounts.join(total_envCounts, \"environment\") \\\n",
    "#    .withColumn(\"quantityVariation\", col(\"count_last_hour\") - col(\"total_count\")) \\\n",
    "#    .withColumn(\"percentageVariation\", col(\"quantityVariation\") / col(\"total_count\") * 100)\n",
    "\n",
    "#envCounts.printSchema()\n",
    "#envCounts.show(5)"
   ],
   "id": "65568e5a3c3b55ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# 5. Calculate the trend\n",
    "statusCounts = statusCounts.withColumn(\"trend\", when(col(\"count_last_hour\") > col(\"total_count\"), \"up\")\n",
    "                                      .when(col(\"count_last_hour\") < col(\"total_count\"), \"down\")\n",
    "                                      .otherwise(\"stable\"))\n",
    "\n",
    "#envCounts = envCounts.withColumn(\"trend\", when(col(\"count_last_hour\") > col(\"total_count\"), \"up\")\n",
    " #                                 .when(col(\"count_last_hour\") < col(\"total_count\"), \"down\")\n",
    " #                                 .otherwise(\"stable\"))\n",
    "\n",
    "statusCounts.printSchema()\n",
    "statusCounts.show(5)\n",
    "\n",
    "#envCounts.printSchema()\n",
    "#envCounts.show(5)\n"
   ],
   "id": "c8fdbb7fe5862048",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "55376a0538ffc421",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "93af423dcfb2c5d6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
